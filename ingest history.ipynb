{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ce88bef-3046-418f-b3cc-ec282f6a2e6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pytz\n",
    "import csv\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import Row  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8d9b8ce-1902-454f-96f6-afc24e0323a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "API_KEY = 'UiuE73uNUuG9AwnT1pRMOLayYw6ZjX4z'\n",
    "BASE_URL = 'https://aeroapi.flightaware.com/aeroapi'\n",
    "\n",
    "headers = {\n",
    "    'x-apikey': API_KEY\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dbacbb1-18e5-49a8-9436-955e5fb0a1f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-01T21:00:00\n2024-09-02T00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Define Malaysia's timezone\n",
    "malaysia_tz = pytz.timezone('Asia/Kuala_Lumpur')\n",
    "\n",
    "# Get the current time in Malaysia\n",
    "malaysia_time = datetime.now(malaysia_tz)\n",
    "\n",
    "# Subtract one and two hours\n",
    "malaysia_time_minus_one_hour = malaysia_time - timedelta(hours=4)\n",
    "malaysia_time_minus_two_hour = malaysia_time - timedelta(hours=5)\n",
    "\n",
    "# Format the time in the desired format\n",
    "start_time_myt = '2024-09-01T21:00:00'\n",
    "end_time_myt = '2024-09-02T00:00:00'\n",
    "\n",
    "airport_code = 'WMKK'\n",
    "\n",
    "print(start_time_myt)\n",
    "print(end_time_myt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0ed35cc-bfd1-4c14-8988-4aed2e31945e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "TRANSFORMATION DEPARTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d93ccb08-2699-408d-906c-cae69f6588e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "time.sleep(65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df48775e-bd62-4a5a-a484-7b0d0f33d148",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-------------+-----------------------+--------------------+------------------+--------------------+----------------+\n|flight_id|flight_number|aircraft_type|scheduled_departure_myt|actual_departure_myt|            origin|         destination|gate_destination|\n+---------+-------------+-------------+-----------------------+--------------------+------------------+--------------------+----------------+\n|   KLM810|          810|        B789 |    2024-09-01 23:55:00| 2024-09-01 23:58:46|Kuala Lumpur Int'l|  Amsterdam Schiphol|              F7|\n|   AXM103|          103|        A320 |    2024-09-01 21:40:00| 2024-09-01 23:55:02|Kuala Lumpur Int'l|Kunming Changshui...|            NULL|\n|   ETH639|          639|        B788 |    2024-09-01 23:30:00| 2024-09-01 23:51:31|Kuala Lumpur Int'l|    Singapore Changi|             E26|\n|  AXM5120|         5120|        A320 |    2024-09-01 23:50:00| 2024-09-01 23:49:10|Kuala Lumpur Int'l| Kota Kinabalu Int'l|            NULL|\n|  MAS1194|         1194|        B738 |    2024-09-01 23:45:00| 2024-09-01 23:47:22|Kuala Lumpur Int'l|        Penang Int'l|            NULL|\n|   KAL672|          672|        A333 |    2024-09-01 23:30:00| 2024-09-01 23:44:47|Kuala Lumpur Int'l|       Incheon Int'l|             248|\n|   MXD318|          318|        B738 |    2024-09-01 19:40:00| 2024-09-01 23:43:13|Kuala Lumpur Int'l|Jakarta-Soekarno-...|            NULL|\n|   MXD820|          820|        B38M |    2024-09-01 22:10:00| 2024-09-01 23:42:08|Kuala Lumpur Int'l|       Incheon Int'l|              27|\n|    AXM29|           29|        A320 |    2024-09-01 22:40:00| 2024-09-01 23:36:43|Kuala Lumpur Int'l|      Tiruchirapalli|            NULL|\n|   MXD713|          713|        B738 |    2024-09-01 23:15:00| 2024-09-01 23:36:01|Kuala Lumpur Int'l|         Dubai Int'l|            NULL|\n|   MAS609|          609|        B738 |    2024-09-01 23:15:00| 2024-09-01 23:19:08|Kuala Lumpur Int'l|    Singapore Changi|             F37|\n|    THY61|           61|        B77W |    2024-09-01 23:15:00| 2024-09-01 23:16:08|Kuala Lumpur Int'l|    Istanbul Airport|            NULL|\n|   MAS196|          196|        B738 |    2024-09-01 23:10:00| 2024-09-01 23:14:26|Kuala Lumpur Int'l|Shahjalal Interna...|            NULL|\n|  AXM5234|         5234|        A320 |    2024-09-01 23:10:00| 2024-09-01 23:12:34|Kuala Lumpur Int'l|       Kuching Int'l|            NULL|\n|   AXM723|          723|        A320 |    2024-09-01 21:45:00| 2024-09-01 23:11:23|Kuala Lumpur Int'l|    Singapore Changi|              G7|\n|   AXM128|          128|        A320 |    2024-09-01 22:10:00| 2024-09-01 23:09:34|Kuala Lumpur Int'l|Shenzhen Bao'an I...|            NULL|\n|   XAX504|          504|        A333 |    2024-09-01 23:00:00| 2024-09-01 23:03:05|Kuala Lumpur Int'l|       Incheon Int'l|             123|\n|   JAL724|          724|        B788 |    2024-09-01 23:00:00| 2024-09-01 23:02:52|Kuala Lumpur Int'l|        Narita Int'l|              72|\n|  MAS2626|         2626|        B738 |    2024-09-01 22:10:00| 2024-09-01 23:00:51|Kuala Lumpur Int'l| Kota Kinabalu Int'l|            NULL|\n|   AWQ127|          127|        A320 |    2024-09-01 22:55:00| 2024-09-01 22:57:42|Kuala Lumpur Int'l|Kuala Namu Intern...|            NULL|\n+---------+-------------+-------------+-----------------------+--------------------+------------------+--------------------+----------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.sql import Row\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    # Replace problematic characters with underscores\n",
    "    return filename.replace(':', '_')\n",
    "\n",
    "def convert_myt_to_utc(myt_time_str):\n",
    "    myt_time = datetime.strptime(myt_time_str, '%Y-%m-%dT%H:%M:%S')\n",
    "    utc_time = myt_time - timedelta(hours=8)\n",
    "    return utc_time.isoformat()\n",
    "\n",
    "def convert_utc_to_myt(utc_time_str):\n",
    "    # Handle missing or invalid date strings\n",
    "    if utc_time_str and utc_time_str != 'N/A':\n",
    "        try:\n",
    "            utc_time = datetime.strptime(utc_time_str, '%Y-%m-%dT%H:%M:%SZ')\n",
    "            myt_time = utc_time + timedelta(hours=8)\n",
    "            return myt_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        except ValueError:\n",
    "            return 'Invalid Date'\n",
    "    else:\n",
    "        return 'N/A'\n",
    "\n",
    "def get_recent_departures(airport_code, start_time_myt, end_time_myt):\n",
    "    start_time_iso = convert_myt_to_utc(start_time_myt) + 'Z'\n",
    "    end_time_iso = convert_myt_to_utc(end_time_myt) + 'Z'\n",
    "    \n",
    "    endpoint = f'{BASE_URL}/airports/{airport_code}/flights/departures'\n",
    "    params = {\n",
    "        'start': start_time_iso,\n",
    "        'end': end_time_iso,\n",
    "        'max_pages':10\n",
    "    }\n",
    "    \n",
    "    response = requests.get(endpoint, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return response.text\n",
    "\n",
    "def convert_to_dataframe_departures(spark, data):\n",
    "    # Define the schema explicitly\n",
    "    schema = StructType([\n",
    "        StructField(\"flight_id\", StringType(), True),\n",
    "        StructField(\"flight_number\", StringType(), True),\n",
    "        StructField(\"aircraft_type\", StringType(), True),\n",
    "        StructField(\"scheduled_departure_myt\", StringType(), True),\n",
    "        StructField(\"actual_departure_myt\", StringType(), True),\n",
    "        StructField(\"origin\", StringType(), True),\n",
    "        StructField(\"destination\", StringType(), True),\n",
    "        StructField(\"gate_destination\", StringType(), True)\n",
    "    ])\n",
    "    \n",
    "    # Create a list of Row objects with safe checks for None\n",
    "    rows = [\n",
    "        Row(\n",
    "            flight_id=flight.get('ident', 'N/A'),\n",
    "            flight_number=flight.get('flight_number', 'N/A'),\n",
    "            aircraft_type=flight.get('aircraft_type', 'N/A'),\n",
    "            scheduled_departure_myt=convert_utc_to_myt(flight.get('scheduled_off', 'N/A')),\n",
    "            actual_departure_myt=convert_utc_to_myt(flight.get('actual_off', 'N/A')),\n",
    "            origin=flight.get('origin', {}).get('name', 'N/A') if flight.get('origin') else 'N/A',\n",
    "            destination=flight.get('destination', {}).get('name', 'N/A') if flight.get('destination') else 'N/A',\n",
    "            gate_destination=flight.get('gate_destination', 'N/A')\n",
    "        )\n",
    "        for flight in data.get('departures', [])\n",
    "    ]\n",
    "    \n",
    "    # Convert the list of Rows into a DataFrame with the predefined schema\n",
    "    df = spark.createDataFrame(rows, schema=schema)\n",
    "    return df\n",
    "\n",
    "# Fetch recent departures\n",
    "recent_departures = get_recent_departures(airport_code, start_time_myt, end_time_myt)\n",
    "\n",
    "# Check if the data is in JSON format\n",
    "if isinstance(recent_departures, dict):\n",
    "    df_departures = convert_to_dataframe_departures(spark, recent_departures)\n",
    "    df_departures.show()  # Display the DataFrame\n",
    "else:\n",
    "    print(\"Error fetching data:\", recent_departures)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b36fe3b-205e-4ac7-9a77-051db19ec61d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "SAVE FILES DEPARTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "805b05f9-d4bc-49ea-92bf-690898af510b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanitize the start time for use in filenames and paths\n",
    "sanitized_start_time = sanitize_filename(start_time_myt)\n",
    "\n",
    "# Define the folder path directly\n",
    "folder_path_departures = '/mnt/raw/departures/'\n",
    "\n",
    "# Coalesce the DataFrame to a single partition\n",
    "df_departures_coalesced = df_departures.coalesce(1)\n",
    "\n",
    "# Write the coalesced DataFrame to a temporary folder\n",
    "temp_folder_path_departures = f\"{folder_path_departures}temp_departures_{sanitized_start_time}/\"\n",
    "df_departures_coalesced.write.mode('overwrite').option('header', 'true').csv(temp_folder_path_departures)\n",
    "\n",
    "# List the files in the temporary folder after writing the CSV file\n",
    "files_departures = dbutils.fs.ls(temp_folder_path_departures)\n",
    "\n",
    "# Filter out the actual CSV file (ignore _SUCCESS and other metadata files)\n",
    "csv_temp_file = [f.path for f in files_departures if f.path.endswith('.csv')][0]\n",
    "\n",
    "# Define the final file path for the CSV file\n",
    "final_csv_file_path_departures = f\"{folder_path_departures}departures_{sanitized_start_time}.csv\"\n",
    "\n",
    "# Move the CSV file to the final destination\n",
    "dbutils.fs.mv(csv_temp_file, final_csv_file_path_departures)\n",
    "\n",
    "# Remove the temporary folder and its contents (_committed_, _started_, _SUCCESS)\n",
    "dbutils.fs.rm(temp_folder_path_departures, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8026658a-2beb-4c22-bf33-cb1499cf1105",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sanitize the start time for use in filenames and paths\n",
    "#sanitized_start_time = sanitize_filename(start_time_myt)\n",
    "\n",
    "# Define the folder path before writing the file\n",
    "#folder_path_departures = f'/mnt/raw/departures/departures_{sanitized_start_time}/'\n",
    "\n",
    "# Coalesce the DataFrame to a single partition\n",
    "#df_departures_coalesced = df_departures.coalesce(1)\n",
    "\n",
    "# Write the coalesced DataFrame to a CSV file in the specified folder\n",
    "#df_departures_coalesced.write.mode('overwrite').option('header', 'true').csv(folder_path_departures)\n",
    "\n",
    "# List the files in the directory after writing the CSV file\n",
    "#files_departures = dbutils.fs.ls(folder_path_departures)\n",
    "\n",
    "# Filter out the actual CSV file (ignore _SUCCESS and other metadata files)\n",
    "#csv_file = [f.path for f in files_departures if f.path.endswith('.csv')][0]\n",
    "\n",
    "# Correct the file path for renaming\n",
    "#corrected_file_path_departures = f\"{folder_path_departures}departures_{sanitized_start_time}.csv\"\n",
    "\n",
    "# Rename the file\n",
    "#dbutils.fs.mv(csv_file, corrected_file_path_departures)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c9af319-39f2-45f3-b1bb-0e309a67bd3b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "TRANSFORMATION ARRIVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b3a554b-69c3-482d-bfee-5b47ab3661e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "time.sleep(65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b500008-b6a4-40a6-bf83-585cf69d749a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-------------+---------------------+-------------------+--------------------+------------------+----------------+\n|flight_id|flight_number|aircraft_type|scheduled_arrival_myt| actual_arrival_myt|              origin|       destination|gate_destination|\n+---------+-------------+-------------+---------------------+-------------------+--------------------+------------------+----------------+\n|  AXM6307|         6307|        A320 |  2024-09-01 22:15:00|2024-09-01 23:56:43|      Langkawi Int'l|Kuala Lumpur Int'l|            NULL|\n|  MXD1007|         1007|        B738 |  2024-09-02 00:00:00|2024-09-01 23:54:24| Kota Kinabalu Int'l|Kuala Lumpur Int'l|            NULL|\n|   CXA823|          823|        B738 |  2024-09-01 23:38:00|2024-09-01 23:50:57|  Xiamen Gaoqi Int'l|Kuala Lumpur Int'l|             C11|\n|   MXD623|          623|        B38M |  2024-09-01 22:57:00|2024-09-01 23:46:46|              Dayong|Kuala Lumpur Int'l|            NULL|\n|   MXD152|          152|        B738 |  2024-09-01 23:52:00|2024-09-01 23:36:26|         Perth Int'l|Kuala Lumpur Int'l|             G10|\n|   MXD523|          523|        B738 |  2024-09-01 23:25:00|2024-09-01 23:29:00|Don Muang Int'l (...|Kuala Lumpur Int'l|              G4|\n|   CES795|          795|        A320 |  2024-09-01 23:00:00|2024-09-01 23:24:13|Beijing Daxing In...|Kuala Lumpur Int'l|             C12|\n|   MXD883|          883|        B38M |  2024-09-01 23:15:00|2024-09-01 23:19:12|Taiwan Taoyuan Int'l|Kuala Lumpur Int'l|              H4|\n|   MAS781|          781|        B738 |  2024-09-01 22:50:00|2024-09-01 23:10:39|Suvarnabhumi Bang...|Kuala Lumpur Int'l|              H4|\n|  AXM6315|         6315|        A320 |  2024-09-01 23:33:00|2024-09-01 23:07:37|      Langkawi Int'l|Kuala Lumpur Int'l|            NULL|\n|   CCA871|          871|        B38M |  2024-09-01 22:35:00|2024-09-01 23:07:00|Beijing Capital I...|Kuala Lumpur Int'l|              C6|\n|  AXM5871|         5871|        A320 |  2024-09-01 21:11:00|2024-09-01 23:00:35|                Sibu|Kuala Lumpur Int'l|            NULL|\n|  MXD1907|         1907|        B738 |  2024-09-01 23:15:00|2024-09-01 22:58:42|                Sibu|Kuala Lumpur Int'l|              A6|\n|  MXD1909|         1909|        B38M |  2024-09-01 23:10:00|2024-09-01 22:54:34|               Tawau|Kuala Lumpur Int'l|              B6|\n|   AXM349|          349|        A320 |  2024-09-01 21:00:00|2024-09-01 22:53:40|Yogyakarta Intern...|Kuala Lumpur Int'l|            NULL|\n|   MAS724|          724|        B738 |  2024-09-01 22:54:00|2024-09-01 22:50:47|Jakarta-Soekarno-...|Kuala Lumpur Int'l|             H10|\n|  MAS2597|         2597|        B738 |  2024-09-01 22:32:00|2024-09-01 22:47:30|       Kuching Int'l|Kuala Lumpur Int'l|             A11|\n|  AXM5121|         5121|        A320 |  2024-09-01 23:00:00|2024-09-01 22:46:42| Kota Kinabalu Int'l|Kuala Lumpur Int'l|            NULL|\n|   AXM720|          720|        A21N |  2024-09-01 22:14:00|2024-09-01 22:44:07|    Singapore Changi|Kuala Lumpur Int'l|            NULL|\n|   AXM379|          379|        A320 |  2024-09-01 22:10:00|2024-09-01 22:38:49|Ngurah Rai/Bali Intl|Kuala Lumpur Int'l|             L12|\n+---------+-------------+-------------+---------------------+-------------------+--------------------+------------------+----------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "def get_recent_arrivals(airport_code, start_time_myt, end_time_myt):\n",
    "    end_time_iso = convert_myt_to_utc(end_time_myt) + 'Z'\n",
    "    start_time_iso = convert_myt_to_utc(start_time_myt) + 'Z'\n",
    "    \n",
    "    endpoint = f'{BASE_URL}/airports/{airport_code}/flights/arrivals'\n",
    "    params = {\n",
    "        'start': start_time_iso,\n",
    "        'end': end_time_iso,\n",
    "        'max_pages':10\n",
    "    }\n",
    "    \n",
    "    response = requests.get(endpoint, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return response.text\n",
    "\n",
    "def convert_to_dataframe_arrivals(spark, data):\n",
    "    # Define the schema explicitly for arrivals\n",
    "    schema = StructType([\n",
    "        StructField(\"flight_id\", StringType(), True),\n",
    "        StructField(\"flight_number\", StringType(), True),\n",
    "        StructField(\"aircraft_type\", StringType(), True),\n",
    "        StructField(\"scheduled_arrival_myt\", StringType(), True),\n",
    "        StructField(\"actual_arrival_myt\", StringType(), True),\n",
    "        StructField(\"origin\", StringType(), True),\n",
    "        StructField(\"destination\", StringType(), True),\n",
    "        StructField(\"gate_destination\", StringType(), True)\n",
    "    ])\n",
    "    \n",
    "    # Create a list of Row objects\n",
    "    rows = [\n",
    "        Row(\n",
    "            flight_id=flight.get('ident', 'N/A'),\n",
    "            flight_number=flight.get('flight_number', 'N/A'),\n",
    "            aircraft_type=flight.get('aircraft_type', 'N/A'),\n",
    "            scheduled_arrival_myt=convert_utc_to_myt(flight.get('scheduled_on', 'N/A')),\n",
    "            actual_arrival_myt=convert_utc_to_myt(flight.get('actual_on', 'N/A')),\n",
    "            origin=flight.get('origin', {}).get('name', 'N/A'),\n",
    "            destination=flight.get('destination', {}).get('name', 'N/A'),\n",
    "            gate_destination=flight.get('gate_destination', 'N/A')\n",
    "        )\n",
    "        for flight in data.get('arrivals', [])\n",
    "    ]\n",
    "    \n",
    "    # Convert the list of Rows into a DataFrame with the predefined schema\n",
    "    df = spark.createDataFrame(rows, schema=schema)\n",
    "    return df\n",
    "\n",
    "# Fetch recent arrivals\n",
    "recent_arrivals = get_recent_arrivals(airport_code, start_time_myt, end_time_myt)\n",
    "\n",
    "# Check if the data is in JSON format\n",
    "if isinstance(recent_arrivals, dict):\n",
    "    df_arrivals = convert_to_dataframe_arrivals(spark, recent_arrivals)\n",
    "    df_arrivals.show()  # Display the DataFrame\n",
    "else:\n",
    "    print(\"Error fetching data:\", recent_arrivals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0778ad3f-25ef-416f-9b3d-ce76c549a19b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "SAVE FILES ARRIVALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be1c3f52-89df-46da-bf30-c4cad603eded",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanitize the start time for use in filenames and paths\n",
    "sanitized_start_time = sanitize_filename(start_time_myt)\n",
    "\n",
    "# Define the folder path directly\n",
    "folder_path_arrivals = '/mnt/raw/arrivals/'\n",
    "\n",
    "# Coalesce the DataFrame to a single partition\n",
    "df_arrivals_coalesced = df_arrivals.coalesce(1)\n",
    "\n",
    "# Write the coalesced DataFrame to a temporary folder\n",
    "temp_folder_path_arrivals = f\"{folder_path_arrivals}temp_arrivals_{sanitized_start_time}/\"\n",
    "df_arrivals_coalesced.write.mode('overwrite').option('header', 'true').csv(temp_folder_path_arrivals)\n",
    "\n",
    "# List the files in the temporary folder after writing the CSV file\n",
    "files_arrivals = dbutils.fs.ls(temp_folder_path_arrivals)\n",
    "\n",
    "# Filter out the actual CSV file (ignore _SUCCESS and other metadata files)\n",
    "csv_temp_file = [f.path for f in files_arrivals if f.path.endswith('.csv')][0]\n",
    "\n",
    "# Define the final file path for the CSV file\n",
    "final_csv_file_path_arrivals = f\"{folder_path_arrivals}arrivals_{sanitized_start_time}.csv\"\n",
    "\n",
    "# Move the CSV file to the final destination\n",
    "dbutils.fs.mv(csv_temp_file, final_csv_file_path_arrivals)\n",
    "\n",
    "# Remove the temporary folder and its contents (_committed_, _started_, _SUCCESS)\n",
    "dbutils.fs.rm(temp_folder_path_arrivals, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "566ca18a-376a-4da5-8c9b-6cddbf62ae61",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sanitize the start time for use in filenames and paths\n",
    "#sanitized_start_time = sanitize_filename(start_time_myt)\n",
    "\n",
    "# Define the folder path before writing the file\n",
    "#folder_path_arrivals = f'/mnt/raw/arrivals/arrivals_{sanitized_start_time}/'\n",
    "\n",
    "# Coalesce the DataFrame to a single partition\n",
    "#df_arrivals_coalesced = df_arrivals.coalesce(1)\n",
    "\n",
    "# Write the coalesced DataFrame to a CSV file in the specified folder (corrected to folder_path_arrivals)\n",
    "#df_arrivals_coalesced.write.mode('overwrite').option('header', 'true').csv(folder_path_arrivals)\n",
    "\n",
    "# List the files in the directory after writing the CSV file\n",
    "#files_arrivals = dbutils.fs.ls(folder_path_arrivals)\n",
    "\n",
    "# Filter out the actual CSV file (ignore _SUCCESS and other metadata files)\n",
    "#csv_file_arrivals = [f.path for f in files_arrivals if f.path.endswith('.csv')][0]\n",
    "\n",
    "# Correct the file path for renaming\n",
    "#corrected_file_path_arrivals = f\"{folder_path_arrivals}arrivals_{sanitized_start_time}.csv\"\n",
    "\n",
    "# Rename the file\n",
    "#dbutils.fs.mv(csv_file_arrivals, corrected_file_path_arrivals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9704128d-d731-436c-b5cc-d2f9a628d6cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n68\n"
     ]
    }
   ],
   "source": [
    "departure_row = df_departures.count()\n",
    "print(departure_row)\n",
    "arrivals_row = df_arrivals.count()\n",
    "print(arrivals_row)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ingest history",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
